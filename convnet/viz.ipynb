{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1, 10)\n",
      "Shape of train_labels_with_zeros: (1001,)\n",
      "Shape of train_data_with_zeros: torch.Size([1001, 10])\n",
      "Indices of class 0: [0]\n",
      "(120, 24)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Convert the dataset to a numpy array for easy indexing\n",
    "# Load embeddings and labels\n",
    "train_data = np.load('/home/maria/Neuromatch2024/convnet/data/embeddings.npy')\n",
    "train_labels = np.load('/home/maria/Neuromatch2024/convnet/data/labels.npy')\n",
    "\n",
    "# Adjust train_labels as per the original intent (adding 1)\n",
    "train_labels = train_labels + 1\n",
    "\n",
    "# Create a row of zeros with the same number of columns as train_data\n",
    "zeros_row = np.zeros((1, train_data.shape[1],))\n",
    "print(train_data.shape, zeros_row.shape)\n",
    "train_data = torch.tensor(\n",
    "    np.vstack((zeros_row, train_data)), dtype=torch.float32).to(device='cuda')\n",
    "\n",
    "# Append the label corresponding to the zeros row\n",
    "train_labels = np.hstack((0, train_labels))\n",
    "\n",
    "print(\"Shape of train_labels_with_zeros:\", train_labels.shape)\n",
    "print(\"Shape of train_data_with_zeros:\", train_data.shape)\n",
    "\n",
    "# Create a dictionary to store indices of each class\n",
    "class_dct = {}\n",
    "for i in range(12):  # Adjusted to iterate from 0 to 10 (inclusive)\n",
    "    class_dct[i] = np.where(train_labels == i)[0]\n",
    "\n",
    "# Print example usage of class_dct\n",
    "print(\"Indices of class 0:\", class_dct[0])\n",
    "\n",
    "\n",
    "# Randomly select one index from class_0_indices\n",
    "# for i in range(100):\n",
    "# random_index = np.random.choice(10)\n",
    "# print(random_index)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple, deque\n",
    "from environment import DelaySampleToMatchEnv\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the Transition namedtuple\n",
    "Transition = namedtuple(\n",
    "    'Transition', ('state', 'action', 'next_state', 'reward', 'hidden', 'next_hidden', 'done'))\n",
    "\n",
    "# agent.store_transition(state, action, reward, next_state, hidden)\n",
    "\n",
    "# next_state, reward, done, info\n",
    "\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class RNNQNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNQNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # print(x.shape)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        # print(out.shape)\n",
    "        q_values = self.fc(out)\n",
    "        return q_values, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.ones(1, 1, self.hidden_size)\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size, action_size, hidden_size, capacity, batch_size, lr, gamma):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.memory = ReplayMemory(capacity)\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.eps_start = 0.99\n",
    "        self.eps_end = 0.01\n",
    "        self.eps_decay = 0.995\n",
    "        self.epsilon = self.eps_start\n",
    "\n",
    "        self.q_network = RNNQNetwork(state_size, hidden_size, action_size)\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        # self.criterion = nn.SmoothL1Loss()\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.q_network.to(self.device)\n",
    "    \n",
    "\n",
    "    def load_model(self):\n",
    "        path= 'rnn_q_network.pth'\n",
    "        checkpoint = torch.load(path)\n",
    "        self.q_network.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.q_network.eval()  \n",
    "\n",
    "    def select_action(self, state, hidden):\n",
    "        rand = random.random()\n",
    "        # print(rand)\n",
    "        if rand > self.epsilon:\n",
    "            with torch.no_grad():\n",
    "                q_values, hidden = self.q_network(\n",
    "                    state.reshape(1, 1, -1), hidden)\n",
    "                action = q_values.max(2).indices.item()\n",
    "        else:\n",
    "            action = random.randrange(self.action_size)\n",
    "        return action, hidden\n",
    "\n",
    "    def store_transition(self, state, action, next_state, reward, hidden, next_hidden, done):\n",
    "        # ('state', 'action', 'next_state', 'reward', 'hidden', 'next_hidden', 'done'))\n",
    "        self.memory.push(state, action, next_state,\n",
    "                         reward, hidden, next_hidden, done)\n",
    "\n",
    "    def learn(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        transitions = self.memory.sample(self.batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        states_tensor = torch.stack(\n",
    "            [s.clone().detach().requires_grad_(True) for s in batch.state]).unsqueeze(0).to(self.device)\n",
    "\n",
    "        hidden_tensor = torch.stack(\n",
    "            [h.clone().detach().requires_grad_(True).squeeze(0).squeeze(0) for h in batch.hidden]).unsqueeze(0).to(self.device)\n",
    "\n",
    "        next_states_tensor = torch.stack(\n",
    "            [s.clone().detach().requires_grad_(True) for s in batch.next_state]).unsqueeze(0).to(self.device)\n",
    "\n",
    "        next_hidden_tensor = torch.stack(\n",
    "            [h.clone().detach().requires_grad_(True).squeeze(0).squeeze(0) for h in batch.next_hidden]).unsqueeze(0).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_q_values, _ = self.q_network(\n",
    "                next_states_tensor, next_hidden_tensor)\n",
    "            next_q_values = next_q_values.max(2).values\n",
    "\n",
    "        rewards_tensor = torch.tensor(\n",
    "            batch.reward, dtype=torch.float32).to(self.device)\n",
    "        actions_tensor = torch.tensor(\n",
    "            batch.action, dtype=torch.int64).to(self.device)\n",
    "        dones_tensor = torch.tensor(\n",
    "            batch.done, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        # Compute current Q-values for all states in the batch\n",
    "        current_q_values, _ = self.q_network(states_tensor, hidden_tensor)\n",
    "\n",
    "        # Remove the leading dimension from current_q_values\n",
    "        current_q_values = current_q_values.squeeze(0)  # Shape [64, 6]\n",
    "\n",
    "        # Expand dimensions of actions_tensor to match the shape required for gather\n",
    "        actions_tensor = actions_tensor.unsqueeze(1)  # Shape [64, 1]\n",
    "\n",
    "        # Gather the q_values corresponding to the actions\n",
    "        current_q_values = current_q_values.gather(\n",
    "            1, actions_tensor)\n",
    "\n",
    "        # Compute target Q-values using the Bellman equation\n",
    "        target_q_values = rewards_tensor + self.gamma * \\\n",
    "            next_q_values * (1 - dones_tensor)\n",
    "\n",
    "        current_q_values = current_q_values.squeeze(1)  # Shape [64]\n",
    "        target_q_values = target_q_values.squeeze(0)\n",
    "        # print(target_q_values.shape, current_q_values.shape)\n",
    "        # Compute the loss\n",
    "        loss = self.criterion(current_q_values, target_q_values)\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.eps_end:\n",
    "            self.epsilon *= self.eps_decay\n",
    "\n",
    "\n",
    "# Example usage\n",
    "state_size = 10\n",
    "action_size = 6\n",
    "hidden_size = 24\n",
    "capacity = 100000\n",
    "batch_size = 100\n",
    "lr = 0.001\n",
    "gamma = 0.99\n",
    "env = DelaySampleToMatchEnv()\n",
    "agent = Agent(state_size, action_size, hidden_size,\n",
    "              capacity, batch_size, lr, gamma)\n",
    "agent.load_model()\n",
    "agent.epsilon = 0.01\n",
    "\n",
    "\n",
    "n_episodes = 10\n",
    "win_pct_list = []\n",
    "scores = []\n",
    "hids=[]\n",
    "\n",
    "for i in range(n_episodes):\n",
    "    done = False\n",
    "    state = env.reset()  # Reset the environment\n",
    "    indices = class_dct[int(state)]\n",
    "    random_index = np.random.choice(indices)\n",
    "    state = train_data[random_index].flatten()\n",
    "    score = 0\n",
    "    hidden = agent.q_network.init_hidden(1).to(agent.device)\n",
    "    while not done:\n",
    "        action, next_hidden = agent.select_action(state, hidden)\n",
    "        next_state, reward, done, info = env.step(action)  # Take the action\n",
    "        indices = class_dct[int(next_state)]\n",
    "        random_index = np.random.choice(indices)\n",
    "        next_state = train_data[random_index].flatten()\n",
    "        # ('state', 'action', 'next_state', 'reward', 'hidden', 'next_hidden', 'done'))\n",
    "        #agent.store_transition(state, action, next_state,\n",
    "                               #reward, hidden, next_hidden, done)\n",
    "        #agent.learn()  # Update Q-network\n",
    "        hidden = next_hidden\n",
    "        #hids.append(hidden)\n",
    "        state = next_state  # Move to the next state\n",
    "        score += reward\n",
    "        \n",
    "        hids.append(hidden.detach().cpu().numpy())\n",
    "        #print(hidden)\n",
    "\n",
    "\n",
    "hids=np.array(hids).squeeze(1).squeeze(1)\n",
    "print(hids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(hids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "2024-07-15 19:53:46,262 [INFO] normalizing data across axis=1\n",
      "2024-07-15 19:53:46,263 [INFO] projecting out mean along axis=0\n",
      "2024-07-15 19:53:46,267 [INFO] data normalized, 0.00sec\n",
      "2024-07-15 19:53:46,268 [INFO] sorting activity: 0 valid samples by 120 timepoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/anaconda3/lib/python3.9/site-packages/rastermap/rastermap.py:291: RuntimeWarning: Mean of empty slice\n",
      "  X_mean = np.nanmean(X, axis=0, keepdims=True).T\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'n_components' parameter of TruncatedSVD must be an int in the range [1, inf). Got 0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m bin_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# fit rastermap\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRastermap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_PCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mlocality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_lag_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_X_embedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m y \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;66;03m# neurons x 1\u001b[39;00m\n\u001b[1;32m     22\u001b[0m isort \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39misort\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/rastermap/rastermap.py:327\u001b[0m, in \u001b[0;36mRastermap.fit\u001b[0;34m(self, data, Usv, Vsv, U_nodes, itrain, compute_X_embedding, BBt)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Usv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 327\u001b[0m     Usv_valid \u001b[38;5;241m=\u001b[39m \u001b[43mSVD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43migood\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43migood\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_PCs\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[1;32m    329\u001b[0m     Usv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(igood), Usv_valid\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    330\u001b[0m     Usv[igood] \u001b[38;5;241m=\u001b[39m Usv_valid\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/rastermap/svd.py:33\u001b[0m, in \u001b[0;36mSVD\u001b[0;34m(X, n_components, return_USV, transpose)\u001b[0m\n\u001b[1;32m     30\u001b[0m nmin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(nmin, n_components)\n\u001b[1;32m     32\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT \u001b[38;5;28;01mif\u001b[39;00m transpose \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m---> 33\u001b[0m U \u001b[38;5;241m=\u001b[39m \u001b[43mTruncatedSVD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transpose:\n\u001b[1;32m     37\u001b[0m     sv \u001b[38;5;241m=\u001b[39m (U\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_truncated_svd.py:223\u001b[0m, in \u001b[0;36mTruncatedSVD.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit model to X and perform dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m        Reduced version of X. This will always be a dense array.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m], ensure_min_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    225\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    593\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 600\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:97\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     )\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'n_components' parameter of TruncatedSVD must be an int in the range [1, inf). Got 0 instead."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "hids=hids\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rastermap import Rastermap, utils\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# spks is neurons by time\n",
    "#spks = np.load(\"spks.npy\").astype(\"float32\")\n",
    "#spks=np.where(np.isnan(hids)==True)\n",
    "spks=hids.T\n",
    "print(spks)\n",
    "spks = zscore(spks, axis=1)\n",
    "bin_size=10\n",
    "\n",
    "# fit rastermap\n",
    "model = Rastermap(n_PCs=10, n_clusters=5, \n",
    "                  locality=0.75, time_lag_window=5).fit(spks, compute_X_embedding=True)\n",
    "y = model.embedding # neurons x 1\n",
    "isort = model.isort\n",
    "\n",
    "# visualize binning over neurons\n",
    "X_embedding = model.X_embedding\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(X_embedding, vmin=0, vmax=1.5, cmap=\"gray_r\", aspect=\"auto\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
